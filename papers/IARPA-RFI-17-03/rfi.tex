\documentclass[12pt,letterpaper]{article}

\usepackage[letterpaper,margin=1in]{geometry}

\usepackage{times}

\usepackage{enumitem}

\usepackage{hyperref}

\title{SDC: Social Dispersed Computing}
\date{}
\begin{document}
\maketitle

\section*{Executive Summary}

The classic Internet architecture assumes computing hosts whose task is to perform computations
and a network of switches and routers whose sole task is to route network packets. This architecture delegates all computing to end-nodes and all communications to the network. However every resource (node or edge) in this architecture has a finite capacity potentially leading to inefficient allocation of resources to communications and computations.  This is the networking model on which our current state of the art cloud computing architectures are built. While this is is sufficient for most tasks it does not scale up when we try to use this architecture in the new emerging pardigm of Digitalization where the boundaries between the network node, the sensor, the actuator are blurring, driven primarily by the internet of things and the smart phone revolution. The data generated via this network is extremely large and needs clever, scalable and possibly decentralized computing solutions that can scale indepently as required. In this network any node in the graph can serve as a computing or network
router node (or both), and  the complex application can possibly be distributed over the network
of these nodes, such that the overall performance (e.g., amount of data processed over
time) is significantly improved.  This is the concept behin the `Social Dispersed Computing', which our groupt has been working on. In this white paper, we describe two usecases for this new computing paradigm and describe the challenges which must be solved.


%Often a complex computational application can be decomposed into computing and
%communication activities. Now if any node in the graph can serve as a computing or network
%router node (or both), then the complex application can possibly be distributed over the network
%of these nodes, such that the overall performance (e.g., amount of data processed over
%time) is signicantly improved. This is the concept behind 'Dispersed Computing' where
%computations are eciently distributed over a number of computing and communication
%resources.
%
%
%Our proposal is about building the technology and tools to create and execute Dispersed
%Computing applications on Network Computation Points (NCP-s): nodes in the network
%that can serve a computers, storage devices, or network routers. The proposed work will focus
%on: (1) developing a technology to model complex software applications (so that they can
%be eectively assigned to NCP-s), (2) designing techniques and tools to continuously monitor
%the resources available at and among the NCP-s, (3) developing ecient distributed algorithms
%to search for resources on the network that can potentially satisfy the requirements
%of the applications (expressed in their models), (4) developing an approach to fault-tolerance
%so that the applications continue functioning even if the NCP-s or the communication links
%between them fail, (5) designing and implementing adaptation strategies so that the running
%application(s) can be dynamically re-allocated to the available resources if those resources
%change over time. The work includes research and development of prototypes, as well as
%experimental evaluation of the technologies developed using realistic applications and scenarios.



%The widespread distribution of 
%
%Power grids are undergoing major changes due to rapid growth in
%renewable energy resources and improvements in battery technology.
%While these changes enhance sustainability and efficiency, they also
%create significant management challenges as the complexity of power
%systems increases.  To tackle these challenges, decentralized
%Internet-of-Things (IoT) solutions are emerging, which may arrange
%local communities into transactive microgrids.  Within a transactive
%microgrid, consumers with energy generation and storage capabilities
%can trade energy with each other, thereby smoothing the load on the
%main grid using local supply. However, it is hard to provide
%security, safety, and privacy in a decentralized and transactive
%energy system.  On the one hand, consumers' personal information must
%be protected from their trade partners and the
%system operator.  On the other hand, the system must be protected from
%careless or malicious trading, which could destabilize the entire
%grid.


\clearpage
\section{Description}
The existing Internet architecture was envisioned more than 30 years ago. This architecture relies on separate computing and communication resources: computing hosts on the edge communicate via a network whose task is to route and deliver network packets as efficiently as possible. This strict separation of computation from communication has its drawbacks: for instance computations that reduce large data sets (arriving from another hosts) to smaller ones (that are needed by another group of hosts) are going to be inefficient, due the limits of network communication. However, often it would be more efficient to move the computation `closer' to the source hosts and then just send the results to the target hosts. A specific example is that of sensor processing: target recognition in sensor streams should be done as close to the source as possible, because doing it somewhere else would incur performance penalties.  Arguably, this is possible today but on an ad-hoc basis. Careful management and deployment of application software components over a network `owned' nodes can be done with a great deal of manual and error-prone operations. These solutions are brittle, labor intensive, and not responsive enough to the rapid changes in the network or the utilization of the computing hosts. 

\subsection{The Social Dispersed Computing Architecture}

The social dispersed computing architecture consists of a number of network computation points (NCP) \footnote{for example,\url{https://routerboard.com/RB2011UiAS-2HnD-IN}}, which posses the capability to provide both networking and computation resources. They can serve as network routers, computing hosts, data storage hosts, sensors,or actuators - in any combination, possibly simultaneously. A typical NCP has router/computer/storage functions, an NCP for cyber-physical applications adds sensor/actuator interfaces to these. A network-connected conventional computing host can serve as an specialized NCP that is connected to the system but it is not capable of routing. These modern networking devices are result of the innovation of software defined networking and the progress made with investments in the Internet of Things technology. Additionally, the architecture consists of smart phones, network links, as well as conventional computing and data storage hosts and as well as network routers. We expect the  NCP-s run a specialized distributed `meta-operating system'  that facilitates the Dispersed Computing functions by providing a sophisticated \textit{distributed application platform} that is able to effectively deploy and executed distributed (dispersed) applications.  Finally, the system is highly dynamic: nodes (NCP-s, computing and data hosts, routers, links) can come (join the system) and go (leave the system) at any time, connectivity and corresponding link parameters: bandwidth, latency, packet drop rate, etc. are changing continuously, and computational and communication demand generated by applications are varying over time. 

With this architecture, computational tasks, described as  a directed graph, where the directed edges represent network flows\footnote{The directed graph can represent both synchronous and asynchronous data flow(s), control flow(s), or a mixture of the two}, can be deployed on these ad-hoc and shared resources. he system is \textit{homogeneous} meaning that any NCP can serve as an entry point to submit an application for deployment into the system. The operating system on the entry point NCP will then execute a time- and depth-bounded search on the system to find a feasible \textit{deployment solution} for the application. A deployment solution is map of the application tasks to NCP-s and the application flows onto network paths. The deployment solution is then implemented: the application tasks are deployed on the selected NCP-s. This search is done via a form of flooding protocol which allows the discovery of necessary resources across several paths at once.  The system is \textit{adaptive} in that even after deployment the deployed configuration may change over time. As the NCP-s continuously monitor themselves and their neighbors, the estimates of the utilization of the resources that was used when the deployment configuration was computed may not be valid forever, it may be imperative to recompute the deployment solution. Additionally, the application itself may evolve and its resource usage may change over time. This necessitates monitoring the application's resource usage over time and updating its model dynamically. If a significant discrepancy between the original state of the system and the resource usage of applications and the current situation is detected, a recomputation of the deployment is initiated.  

The effective deployment of these complex assemblies on a network of computing nodes is a non-trivial task and requires significant manual labor today. The proposed framework will provide the foundation for this new software paradigm: applications deployed on a network of computing and communicating devices, where they can be the most effective, given computational and communication resource constraints. This deployment configuration computed during operations, based on the current state of the system. The deployment is also adaptive: computation and data can move in the system, as the changing conditions necessitate it. This is much more flexible and very different from the existing, typically static deployments. 

There are a number of distributed software frameworks, e.g. Erlang/OTP, Akka, etc. that support the development of distributed applications. However, the distribution is completely in the hand of the developer, and it is mainly an error-prone and complex manual task. Our approach, through the application modeling, enables the automation of this process. Although the application models still need to be supplied, the determination of the deployment and the execution of the necessary operations will be completely automated. 

Fault tolerance and adaptivity to changing resources are important requirements for many systems. Our approach, through the underlying framework provides a solution so that complex applications can operate autonomously and efficiently, even under adversary conditions. Both fault tolerance and adaptivity require cooperation from the developers - i.e. the application framework cannot solve the problem, but the framework will provide services to help achieve the required system level fault-tolerance and adaptivity.  However, there are additional challenges, which we will describe using two case studies. The first one looks at the transactive energy pardigm, the other looks at multi-modal transporation analytics and optimization, a critical concept that is required to solve the large transportation challenges that we are facing. 

\subsection{Transactive Grid Example}

Transactive energy models have
been proposed to support the next distribution system evolution
\cite{kok2016society,cox2013structured,melton2013gridwise}. Transactive
energy is a set of market-based constructs for dynamically balancing
the demand and supply across the electrical infrastructure
\cite{melton2013gridwise}. In this approach, customers on the same
feeder (\emph{i.e.}, those sharing a power line link) can operate in an
open market, trading and exchanging generated energy
locally. Distribution System Operators (DSOs) can be the custodians of
this market, while still meeting the net demand \cite{7462854}. For
example, the Brooklyn Microgrid, which was developed by LO3 Energy as
a pilot project, is a peer-to-peer market for locally generated
renewable energy.\footnote{\url{http://brooklynmicrogrid.com/}}.

These systems are effectively an example of social dispersed computing (Volttron \cite{katipamula2016volttron}, OpenFMB
\cite{gunthersmart}, and the Resilient Information Architecture
Platform for Smart Grid (RIAPS)
\cite{eisele2017riaps,Scott2017ICCPS}) where consumer power storage and private energy sources as solar panels, achieving grid stability will be challenging.  With social dispersed computing in transactive grid energy consumers, producers, storage solutions will be discovered automatically, continuously monitored and the system status is updated in case devices appear to be offline. However, the computing structure in these systems do not focus on the  privacy challenges that arise from the
required information exchange in this decentralized transactive
system: 
\begin{itemize}[itemsep=0.1\parskip,topsep=-0.75\parskip]
\item \textbf{Leakage of Energy Usage Patterns to Other Prosumers} 
 Since prosumers\footnote{We
  refer to customers as \emph{prosumers} to emphasize that they can
  not only consume energy, but may also produce it.} may purchase
  energy from each other in a transactive microgrid, transactions may
  inadvertently reveal the prosumers' detailed energy usage patterns
  to other prosumers within the microgrid.  Addressing this issue in a
  decentralized trading system is hard as it requires hiding the
  identities of trade partners from each other. In comparison, secure
  smart metering reveals the prosumers' energy usage patterns only to
  the operator.

\item \textbf{Inference of Future States of a Prosumer} 
  Transactions may reveal
  the future energy usage of a prosumer, which could be used to infer
  private information.  For example, a smart home may know that its
  inhabitants will go out in the evening (\emph{e.g.}, by looking at
  their calendar), and it may trade energy futures accordingly in the
  morning.  Without adequate privacy measures, these trades may reveal
  to other prosumers in the microgrid that the inhabitants will not be
  at home later.  Note that energy
  futures, whose delivery may happen several hours after when the
  transaction is made, can play an important role in predicting and
  controlling microgrid load.  In comparison, smart metering reveals
  only current (or past) usage.

\item \textbf{Personally Identifiable Information} 
  Transactions and energy
  usage data in a transactive microgrid are much richer sources of
  information than the simple usage data collected by smart
  meters.  Specifically, the information available in a
  transactive microgrid is a superset of what is available from smart
  metering, and it may be used to infer personal information, such as
  risk propensity and financial standing.
\end{itemize}
\vspace{0.5\parskip}

Before transactive energy systems can be deployed widely in practice,
we must address the privacy issues described above. However, addressing these
issues is hard since solutions must also satisfy security
and safety requirements, which often conflict with privacy goals.  For
example, to prevent a prosumer from destabilizing the grid through
careless of malicious energy trading, the system must check all of the
prosumer's transactions.  

\subsection{Distributed Processing for Multimodal Routing}

Urban spaces are expanding at impressive rates and an efficient transportation system is a key component to any well-functioning city. Yet, as cities expand, existing infrastructures are being stressed to their limits. To make the problem worse,  building new infrastructures is costly, time consuming, and disruptive. Consequently, a number of transit agencies and cities are turning towards multimodal  solutions combining transporation operated by both cities and private users. However, given the large number of choices and available options this often leads to a dynamic programming problem that must be solved online considering serveral state variables, such as traffic congenstion, mode capacity and the personal preferences. 

Many commercially available Internet of Things (IoT) solutions for multimodal
transit focus on what is best for the individual from their local perspective. For example, Google Maps is able to chose between multiple options like busing, driving and biking for an individual user. But as the number of these locally optimal solution grows, too grows the misalignment between objectives of individual users and the overall system. This gap often results in a tragedy of the commons, where public goods such as roads become congested although no individual user has an incentive to use other modes of transportation. At the same time, an information bottleneck is also forming. Large scale data is being collected both by municipalities and users, but neither has the resources on their own to develop real-time analytics and controls necessary for a smart transportation system. Currently, very little has been done to provide an overarching solution that balances the needs of multiple parties including commercial companies, municipal service providers, and individuals.

\subsection{The privacy problem}
A solution to this problem requires a social computing and information sharing platform that overcomes the incentive gap between individuals and municipalities. This platform must offer mixed-mode routing suggestions and general system information to travelers and in turn provides service providers with high-fidelity information about how users are consuming different transportation resources. At the same time, this system must consider the investment required by the cities in the computing infrastructure required to solve the problem at scale. Alternatively, a novel proof-of-concept that utilizes the various edge computing resources available in the city, including the mobile devices of the commuters can be employed by municipalities to improve efficiency within their cities with little investment.

However, this precisely leads to the problem of secure and trustworthy computing.  Privacy of individuals is an important aspect of this solution; use of smart devices of individuals as both a data source and a computational resource  could have the effect of exposing the end-user to risk of a privacy breach. Seemingy innocuous data such as transit mode or route choice can lead to inferences of
private information such as real-time tracking of an individual's position~\cite{koufogiannis:2015aa}, likelihood of affairs~\cite{mueffelmann:2015aa}, forecasting trip destinations~\cite{dewri:2013aa}, etc.


\clearpage
\bibliographystyle{plain}
\bibliography{../IoT2017/references}

\end{document}

